{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T07:27:01.258528Z",
     "start_time": "2024-11-23T07:26:57.938513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "dataset = load_dataset(\"openwebtext\", trust_remote_code=True) # 45 mins first time, after that 1.5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f03459056c43a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T07:27:53.658542Z",
     "start_time": "2024-11-23T07:27:53.402228Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load vocab\n",
    "flyvec_embeddings_path = 'simple-flyvec-embeddings.json'\n",
    "with open(flyvec_embeddings_path, 'r') as file:\n",
    "    embeddings = json.load(file)\n",
    "\n",
    "\n",
    "vocab = {word: idx for idx, word in enumerate(embeddings.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694ca51d45abe7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T08:12:12.247401Z",
     "start_time": "2024-11-23T07:27:55.055610Z"
    }
   },
   "outputs": [],
   "source": [
    "from encoder import Encoder\n",
    "from flyvec_model import FlyvecModel\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "encoder = Encoder(vocab=vocab)\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = FlyvecModel(\n",
    "    K_size=400,            # Number of neurons\n",
    "    vocab_size=len(vocab),  # Size of vocab\n",
    "    k=1,                    # Update top-k neurons\n",
    "    lr=.2,                  # Learning rate\n",
    "    norm_rate=1,            # Normalization rate\n",
    "    create_target_vector=True\n",
    ")\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "id_counter = Counter()\n",
    "windows_count = 0\n",
    "passage_count = 0\n",
    "\n",
    "for passage in tqdm(dataset['train'], desc=\"Processing Passages\"):\n",
    "    passage_count += 1\n",
    "\n",
    "    text = passage['text']\n",
    "    preprocessed_text = encoder.preprocess(text, remove_stopwords=True)\n",
    "\n",
    "    words_arr = np.array(preprocessed_text)\n",
    "    words_arr = words_arr[:len(words_arr) - len(words_arr) % window_size]\n",
    "    train_data = words_arr.reshape(-1, window_size)\n",
    "\n",
    "    for window in train_data:\n",
    "        tokenized_window = encoder.tokenize(window.tolist())\n",
    "        one_hot = encoder.one_hot(tokenized_window, create_target_vector=True)\n",
    "        model.update(one_hot)\n",
    "        windows_count += 1\n",
    "        id_counter.update(tokenized_window)\n",
    "\n",
    "    # Save the model every 80,000 (1% of dataset)\n",
    "    if passage_count % 80000 == 0:\n",
    "        pct = passage_count // 80000\n",
    "        utils.save_model(model, f\"trained_models/original_openwebtext_checkpoints/model_checkpoint_{pct}pct.pt\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db50022c470ed91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T08:12:14.290539Z",
     "start_time": "2024-11-23T08:12:14.271633Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counter = {word: id_counter.get(id, 0) for word, id in vocab.items()}\n",
    "word_counter = dict(sorted(word_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1df8a53ae8ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T08:13:07.601554Z",
     "start_time": "2024-11-23T08:13:06.081881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find words with embeddings most similar to the target word embedding\n",
    "target_word = 'bird'\n",
    "hash_length = 40\n",
    "top_N_closest = 20\n",
    "\n",
    "#model = utils.load_model('trained_models/.pt')\n",
    "import utils\n",
    "\n",
    "utils.calc_print_sim_words(\n",
    "    vocab=vocab,\n",
    "    word_counts=word_counter,\n",
    "    model=model,\n",
    "    word=target_word,\n",
    "    hash_len=hash_length,\n",
    "    top_N=top_N_closest,\n",
    "    create_target_vector=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb069bd342bbb7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
