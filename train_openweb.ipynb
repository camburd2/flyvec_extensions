{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T07:26:06.853492Z",
     "start_time": "2024-11-23T07:06:40.777822Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "dataset = load_dataset(\"openwebtext\", trust_remote_code=True) # 45 mins first time, after that 1.5 mins"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0/21 [00:00<?, ?files/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4939f4d566a34205af174dfe48c2b8a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "urlsf_subset12.tar:  52%|#####2    | 325M/624M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "466f0e6cd0f943f8b3056dfcfae3bb12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6da11e6f42bc4aaab14095bb517042b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "451473f9b49b4db6a683acf8e044d83a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load vocab\n",
    "flyvec_embeddings_path = 'simple-flyvec-embeddings.json'\n",
    "with open(flyvec_embeddings_path, 'r') as file:\n",
    "    embeddings = json.load(file)\n",
    "\n",
    "\n",
    "vocab = {word: idx for idx, word in enumerate(embeddings.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Passages:  18%|█▊        | 1437786/8013769 [9:55:20<45:22:54, 40.25it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m tokenized_window \u001B[38;5;241m=\u001B[39m encoder\u001B[38;5;241m.\u001B[39mtokenize(window\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[0;32m     38\u001B[0m one_hot \u001B[38;5;241m=\u001B[39m encoder\u001B[38;5;241m.\u001B[39mone_hot(tokenized_window)\n\u001B[1;32m---> 39\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mone_hot\u001B[49m\u001B[43m)\u001B[49m       \n\u001B[0;32m     40\u001B[0m windows_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m  \n\u001B[0;32m     41\u001B[0m id_counter\u001B[38;5;241m.\u001B[39mupdate(tokenized_window)\n",
      "File \u001B[1;32mc:\\Users\\camer\\Downloads\\only_context_flyvec-20241119T182725Z-001\\only_context_flyvec\\clean\\flyvec_extensions\\context_model.py:39\u001B[0m, in \u001B[0;36mContextModel.update\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcount \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_rate:\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcount \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_mask] \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_mask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm_mask\u001B[38;5;241m.\u001B[39mzero_()\n",
      "File \u001B[1;32mc:\\Users\\camer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4753\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(input, p, dim, eps, out)\u001B[0m\n\u001B[0;32m   4751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(normalize, (\u001B[38;5;28minput\u001B[39m, out), \u001B[38;5;28minput\u001B[39m, p\u001B[38;5;241m=\u001B[39mp, dim\u001B[38;5;241m=\u001B[39mdim, eps\u001B[38;5;241m=\u001B[39meps, out\u001B[38;5;241m=\u001B[39mout)\n\u001B[0;32m   4752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4753\u001B[0m     denom \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp_min\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_as\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4754\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m/\u001B[39m denom\n\u001B[0;32m   4755\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from encoder import Encoder\n",
    "from flyvec_model import FlyvecModel\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "encoder = Encoder(vocab=vocab)\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = FlyvecModel(\n",
    "    K_size= 400,            # Number of neurons\n",
    "    vocab_size=len(vocab),  # Size of vocab\n",
    "    k=5,                    # Update top-k neurons\n",
    "    lr=.1,                  # Learning rate\n",
    "    norm_rate=5             # Normalization rate\n",
    ")\n",
    "\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "id_counter = Counter()\n",
    "windows_count = 0\n",
    "passage_count = 0\n",
    "\n",
    "for passage in tqdm(dataset['train'], desc=\"Processing Passages\"):\n",
    "    passage_count += 1\n",
    "\n",
    "    text = passage['text']\n",
    "    preprocessed_text = encoder.preprocess(text, remove_stopwords=True)\n",
    "\n",
    "    words_arr = np.array(preprocessed_text)\n",
    "    words_arr = words_arr[:len(words_arr) - len(words_arr) % window_size]\n",
    "    train_data = words_arr.reshape(-1, window_size)    \n",
    "\n",
    "    for window in train_data:\n",
    "        tokenized_window = encoder.tokenize(window.tolist())\n",
    "        one_hot = encoder.one_hot(tokenized_window)\n",
    "        model.update(one_hot)       \n",
    "        windows_count += 1  \n",
    "        id_counter.update(tokenized_window)\n",
    "        \n",
    "    # Save the model every 80,000 (1% of dataset)\n",
    "    if passage_count % 80000 == 0:\n",
    "        pct = passage_count // 80000\n",
    "        utils.save_model(model, f\"trained_models/context_openwebtext_checkpoints/model_checkpoint_{pct}pct.pt\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = {word: id_counter.get(id, 0) for word, id in vocab.items()}\n",
    "word_counter = dict(sorted(word_counter.items(), key=lambda x: x[1], reverse=True))\n",
    "word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Similarity Frequency \n",
      "-----------------------------------\n",
      "concert             1.000      24579\n",
      "missed              0.770      55568\n",
      "pop                 0.770      62099\n",
      "diet                0.770      38875\n",
      "mood                0.770      24341\n",
      "lyrics              0.770      17302\n",
      "swift               0.770      22656\n",
      "coat                0.765      14766\n",
      "remaining           0.765      62704\n",
      "noticeable          0.765       9035\n",
      "essay               0.760      19074\n",
      "instrumental        0.760      10018\n",
      "impoverished        0.760       5335\n",
      "types               0.760      93433\n",
      "father              0.760     168250\n",
      "located             0.760      70000\n",
      "songs               0.760      57015\n",
      "injection           0.760      13946\n",
      "invest              0.760      29146\n",
      "memo                0.760      19636\n"
     ]
    }
   ],
   "source": [
    "# Find words with embeddings most similar to the target word embedding\n",
    "target_word = 'concert'\n",
    "hash_length = 70\n",
    "top_N_closest = 20\n",
    "\n",
    "#model = utils.load_model('trained_models/.pt')\n",
    "import utils\n",
    "\n",
    "utils.calc_print_sim_words(\n",
    "    vocab=vocab,\n",
    "    word_counts=word_counter,\n",
    "    model=model,\n",
    "    word=target_word,\n",
    "    hash_len=hash_length,\n",
    "    top_N=top_N_closest\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
