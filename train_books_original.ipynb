{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T21:38:40.002485Z",
     "start_time": "2024-11-22T21:38:39.999553Z"
    }
   },
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "from context_model import ContextModel\n",
    "import preprocess_books as prep\n",
    "import utils"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/naturalhg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T21:38:54.447586Z",
     "start_time": "2024-11-22T21:38:53.227335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data and combine books into a string\n",
    "combined_books_text = prep.load_book_data('data/train.json')\n",
    "\n",
    "# Clean/filter text\n",
    "words_list, word_counts, vocab = prep.preprocess_text(combined_books_text)\n",
    "print(f'Number of words: {len(words_list)}')\n",
    "print(f'Number of unique words: {len(vocab)}')\n",
    "total_num_of_words = len(words_list)\n",
    "vocab_possibility = []\n",
    "for word in vocab:\n",
    "    vocab_possibility.append(word_counts[word] / total_num_of_words)\n",
    "#check if the vocab_possibility sum to 1\n",
    "print(f'Vocab possibility sum: {sum(vocab_possibility)}')\n",
    "#put back to tensor\n",
    "vocab_possibility = torch.tensor(vocab_possibility + vocab_possibility)\n",
    "\n",
    "\n",
    "train_data = prep.prepare_training_data(words_list, window_size=10)\n",
    "\n",
    "print(f'train data shape: {train_data.shape}')\n",
    "print(f'train sample: {random.choice(train_data)}')"
   ],
   "id": "45197d6a8bf16322",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 2324461\n",
      "Number of unique words: 6132\n",
      "Vocab possibility sum: 1.0000000000000002\n",
      "train data shape: (232446, 10)\n",
      "train sample: ['surprised' 'gentleman' 'experienced' 'change' 'feeling' 'drew' 'back'\n",
      " 'chair' 'took' 'newspaper']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-22T21:40:08.758065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from original_model import OriginalModel\n",
    "\n",
    "model = OriginalModel(\n",
    "    N_size=len(vocab),\n",
    "    kc_size=350,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "from utils import Encoder\n",
    "# Create encoder\n",
    "enc = utils.Encoder(vocab)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 15\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for num, sample in enumerate(tqdm(train_data, desc=f'Epoch {i+1}/{num_epochs}', ncols=100, leave=True)):\n",
    "        enc_sample = enc.one_hot(sample, create_target_vector=True)\n",
    "        model.learning(enc_sample, vocab_possibility, learning_rate=0.1)\n",
    "    model.save_checkpoint(f'trained_models/original_model_epoch{i+1}_books.pt')\n",
    "        "
   ],
   "id": "6a14f82c935d134a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|█████████████████████████████████████████| 232446/232446 [00:43<00:00, 5306.99it/s]\n",
      "Epoch 2/15:   7%|██▊                                       | 15361/232446 [00:03<00:44, 4869.56it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
