{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-23T06:34:28.826047Z",
     "start_time": "2024-11-23T06:34:28.821506Z"
    }
   },
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#disable ssl\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from flyvec_model import FlyvecModel\n",
    "import preprocess_books as prep\n",
    "import utils"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/naturalhg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T06:34:39.129914Z",
     "start_time": "2024-11-23T06:34:38.047531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data and combine books into a string\n",
    "combined_books_text = prep.load_book_data('data/train.json')\n",
    "\n",
    "# Clean/filter text\n",
    "words_list, word_counts, vocab = prep.preprocess_text(combined_books_text)\n",
    "\n",
    "# Create training data: np array shape [N, window_size]\n",
    "train_data = prep.prepare_training_data(words_list, window_size=10)\n",
    "\n",
    "print(f'train data shape: {train_data.shape}')\n",
    "print(f'train sample: {random.choice(train_data)}')"
   ],
   "id": "e9c008a502515367",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (232446, 10)\n",
      "train sample: ['noise' 'heat' 'joy' '<unk>' '<unk>' 'noon' 'day' 'received' 'note'\n",
      " 'went']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T06:44:35.694109Z",
     "start_time": "2024-11-23T06:41:14.283605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create model\n",
    "model = FlyvecModel(\n",
    "    K_size=350,            # Number of neurons\n",
    "    vocab_size=len(vocab),  # Size of vocab\n",
    "    k=1,                    # Update top-k neurons\n",
    "    lr=.2,                  # Learning rate\n",
    "    norm_rate=1,            # Normalization rate\n",
    "    create_target_vector=True\n",
    ")\n",
    "\n",
    "# Create encoder\n",
    "enc = utils.Encoder(vocab)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 10\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for num, sample in enumerate(tqdm(train_data, desc=f'Epoch {i+1}/{num_epochs}', ncols=100, leave=True)):\n",
    "        enc_sample = enc.one_hot(sample, create_target_vector=True)\n",
    "        model.update(enc_sample)\n",
    "\n",
    "# Save model\n",
    "utils.save_model(model, f'trained_models/original_model_epoch{num_epochs}_books.pt')"
   ],
   "id": "f86f615a1cd81670",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████████████████████| 232446/232446 [00:18<00:00, 12739.85it/s]\n",
      "Epoch 2/10: 100%|████████████████████████████████████████| 232446/232446 [00:19<00:00, 11979.43it/s]\n",
      "Epoch 3/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11532.27it/s]\n",
      "Epoch 4/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11599.49it/s]\n",
      "Epoch 5/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11133.17it/s]\n",
      "Epoch 6/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11342.56it/s]\n",
      "Epoch 7/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11068.89it/s]\n",
      "Epoch 8/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11226.99it/s]\n",
      "Epoch 9/10: 100%|████████████████████████████████████████| 232446/232446 [00:20<00:00, 11491.91it/s]\n",
      "Epoch 10/10: 100%|███████████████████████████████████████| 232446/232446 [00:20<00:00, 11500.46it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T06:44:39.182230Z",
     "start_time": "2024-11-23T06:44:38.898437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find words with embeddings most similar to the target word embedding\n",
    "target_word = 'ship'\n",
    "hash_length = 40\n",
    "top_N_closest = 20\n",
    "\n",
    "#model = utils.load_model('trained_models/original_model_epoch3_books.pt')\n",
    "\n",
    "utils.calc_print_sim_words(\n",
    "    vocab=vocab,\n",
    "    word_counts=word_counts,\n",
    "    model=model,\n",
    "    word=target_word,\n",
    "    hash_len=hash_length,\n",
    "    top_N=top_N_closest,\n",
    "    create_target_vector=True\n",
    ")"
   ],
   "id": "598b030e4c212a7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Similarity Frequency \n",
      "-----------------------------------\n",
      "ship                1.000       1203\n",
      "springing           0.880         61\n",
      "wreck               0.869        101\n",
      "spots               0.869         75\n",
      "assist              0.863        139\n",
      "consideration       0.863        258\n",
      "nations             0.863        111\n",
      "cause               0.863        661\n",
      "cattle              0.863         96\n",
      "intense             0.863        152\n",
      "mantle              0.863         61\n",
      "flies               0.863         92\n",
      "cartridges          0.863         52\n",
      "deaf                0.857         65\n",
      "secure              0.857        213\n",
      "journal             0.857        145\n",
      "purely              0.857         76\n",
      "trembled            0.857        182\n",
      "prevailed           0.857         77\n",
      "submit              0.857         85\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
